[{"content":"Work performed as a Computing Scholar Intern at Lawrence Livermore National Lab.\nMachine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA Abstract: Groundwater ages provides insight into recharge rates, flow velocities, and vulnerability to contaminants. The ability to predict groundwater ages based on more accessible parameters via Machine Learning (ML) would advance our ability to guide sustainable management of groundwater resources. In this study, ML models were trained and tested on a large dataset of tritium concentrations ($n=2410$) and tritium-helium groundwater ages ($n=1157$) from the California Central Valley, a large groundwater basin with complex land use, irrigation, and water management practices. The ML models were trained on $63$ features, including location, well construction information, landscape characteristics, and climate variables, water chemistry, and stable isotopes. The Bagging Regressor ML method can accurately classify (F1-score = $0.91$) groundwater samples as either modern or pre-modern whereas the accuracy of the ML prediction of continuous tritium-helium groundwater ages is limited and explains only $\\sim 30%$ of the variability in this dataset. In general, ML groundwater age prediction relies mostly on features related to (1) the source of groundwater recharge, (2) contaminant history, (3) aquifer materials, (4) well construction, and (5) geochemical reactions along flow paths. Link to Preprint ","permalink":"https://azhara001.github.io/publications-and-preprints/ground-water-predictions/","summary":"Azhar, A., Chakraborty, I., Visser, A., Liu, Y., Lerback, J. C., \u0026amp; Oerter, E. Machine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA. California, USA.","title":"Machine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA"},{"content":"FINE-TUNING VISION TRANSFORMER-BASED MODEL FOR POSE-ESTIMATION Abstract: With the development of the Computer Vision discipline within Deep Learning, Pose Estimation tasks have seen increasing interest and growth in the past decade. Pose Estimation refers to the problem of localizing specific body parts in images and videos and encoding the spatial information into a caption relating human skeletal joints with pixel coordinates. While Pose Estimation models have largely been Convolutional Neural Network (CNN)-based, the advent of Vision Transformers (ViT) has opened new areas of research. In this study, we fine-tune a transformer-based model, BLIP, to generate accurate positional captions and explore attention mechanisms under this task. Starting with a low-complexity version of our problem, we scaled up to our task of fine-tuning BLIP for Pose Estimation. After fine-tuning BLIP on varying hyperparameters, we found that the model consistently performed well during tuning. Within a restricted threshold of 1 pixel, it retained an 81% validation accuracy and an average error of about 4 pixels. Link to Preprint Code ","permalink":"https://azhara001.github.io/publications-and-preprints/blip/","summary":"Jinxuan Liang, Yihua Zhou, Abdullah Azhar, Anjana Manjunath University of California, Berkeley","title":"Human Pose Estimation using BLIP"},{"content":" Fine-Tuning BLIP for Pose Estimation\nLinks: Preprint Poster Github Abstract: With the development of the Computer Vision discipline within Deep Learning, Pose Estimation tasks have seen increasing interest and growth in the past decade. Pose Estimation refers to the problem of localizing specific body parts in images and videos and encoding the spatial information into a caption relating human skeletal joints with pixel coordinates. While Pose Estimation models have largely been Convolutional Neural Network (CNN)-based, the advent of Vision Transformers (ViT) has opened new areas of research. In this study, we fine-tune a transformer-based model, BLIP, to generate accurate positional captions and explore attention mechanisms under this task. Starting with a low-complexity version of our problem, we scaled up to our task of fine-tuning BLIP for Pose Estimation. After fine-tuning BLIP on varying hyperparameters, we found that the model consistently performed well during tuning. Within a restricted threshold of 1 pixel, it retained an 81% validation accuracy and an average error of about 4 pixels.\n","permalink":"https://azhara001.github.io/projects/fine-tuning-blip/","summary":"Fine-Tuning BLIP (Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation) Vision-based Transformer Model For Human-Pose Estimation","title":"Fine Tuning BLIP"},{"content":" Fine-Tuning DONUT for Fabric Composition\nLinks: Github Motivation ","permalink":"https://azhara001.github.io/projects/fine-tuning-donut/","summary":" Fine-Tuning DONUT for Fabric Composition\nLinks: Github Motivation ","title":"Fine Tuning OCR-Free DONUT Model for Image-to-Text Retrieval (in progress)"},{"content":" Canonical Basis (EigenFaces)\nLinks: Github Description: The \u0026ldquo;Facial Recognition using Fisher Faces vs Eigen Faces with Support Vector Machines\u0026rdquo; project aimed to develop a robust face recognition algorithm leveraging supervised learning techniques. Two feature extraction methods were explored: Eigenfaces and Fisherfaces. Support Vector Machines (SVMs) were then trained using these features to classify faces accurately.\nDatasets Used: Olivetti Dataset: 400 images, 40 classes, 4096 features per image. Labelled Faces in the Wild (LFW) Dataset: 1850 images, user-defined classes, 62500 features per image. Labelled Faces in the Wild (unprocessed) Dataset: 62500 features per image. Methodology: Feature Extraction: Eigenfaces: Utilized PCA to extract eigenfaces from the image datasets. Fisherfaces: Implemented Fisher Linear Discriminant Analysis (FLDA) to extract discriminant features.\nClassification: SVMs with Linear and Radial Basis Function (RBF) kernels were trained using the extracted features.\nEvaluation: The performance of classifiers was evaluated using metrics like accuracy, precision, recall, and F1-score. Exploratory Data Analysis (EDA) techniques such as t-SNE visualization were employed to analyze dataset distributions.\nKey Findings: Eigenfaces vs Fisherfaces: Fisherfaces showed improved classification performance compared to Eigenfaces, especially for complex datasets. SVM Kernel Comparison: Linear SVMs outperformed non-linear (RBF) SVMs for most datasets. Dataset Complexity: Performance varied based on dataset complexity, with higher accuracy achieved on simpler datasets. Impact of Dimensionality Reduction: Dimensionality reduction techniques like PCA significantly influenced classifier performance. Conclusion: The project demonstrated the efficacy of Fisherfaces combined with SVMs for face recognition tasks. By comparing different feature extraction methods and SVM configurations, valuable insights were gained into the nuances of facial recognition systems. The findings contribute to the ongoing research in computer vision and pattern recognition domains, paving the way for more accurate and efficient face recognition algorithms\n","permalink":"https://azhara001.github.io/projects/facial-recognition/","summary":"Facial Recognition (classification) from eigenfaces and fisher faces canoncial basis using Soft-Margin Support Vector Machines","title":"Facial Recognition using eigenfaces/fisherfaces using an SVM Classifier"},{"content":" Spatio-temporal Heat Map\nLinks: Article Poster Github Conference Presentation Description: This project delved into the intricate relationship between school closures, traffic congestion, and smog in Lahore, Pakistan. As part of the Smart Data Systems and Applications (SDSA) team at Lahore University of Management Sciences (LUMS), we aimed to leverage data-driven analysis to understand the effectiveness of closing schools on Mondays in reducing traffic congestion and ultimately alleviating smog.\nObjectives: Investigate the impact of school closure policies on traffic congestion levels in Lahore. Analyze the correlation between traffic congestion reduction and improvements in air quality, particularly regarding smog levels. Provide insights and recommendations based on data-driven findings to inform future policy decisions and urban planning initiatives.\nMethodology: Utilized the Google Maps Platform to extract data on travel times, routes, and congestion levels in Lahore. Conducted data preprocessing, including normalization of travel times and comparison of velocities to assess traffic congestion. Employed statistical analysis techniques to interpret the impact of school closures on traffic congestion before and during the winter break. Visualized findings through graphs, heatmaps, and geospatial mapping to facilitate understanding and communication of results.\nResults: Identified a significant decrease in traffic congestion on Mondays, particularly during the winter break when schools were closed. Observed a correlation between reduced traffic congestion and improvements in air quality, indicating the potential effectiveness of school closure policies in mitigating smog. Highlighted Thursdays as a day with the greatest decrease in congestion, suggesting alternative strategies beyond Mondays for reducing traffic congestion and smog.\nConclusion: This project sheds light on the efficacy of school closure policies in addressing traffic congestion and smog in Lahore. By providing actionable insights derived from data analysis, we intended to inform policymakers, urban planners, and stakeholders about effective strategies for mitigating the impact of smog in the region. Our findings underscored the importance of proactive measures and evidence-based decision-making in tackling environmental challenges like smog.\n","permalink":"https://azhara001.github.io/projects/travel-times-analysis/","summary":"Exploring the bittersweet relationship of schools‚Äô closure and smog ‚Äì an effective step in alleviating traffic congestions?","title":"Analyzing Spatio-Temporal Travel Times using Crowd-sourced Data"},{"content":" üìö Coursework: 1. Designing, Visualizing, and Understanding Deep Neural Networks [ course website, final project, github ] Topics Covered: Choice of optimizers (Stochastic Gradient Descent, Adam, Adam with Momentum) Convolutional Neural Networks, Skip Connections, Batch Normalization Recurrent Neural Networks Transformers (cross-attention, self-attention, argmax attention), Fine-Tuning, Parameter-Efficient Fine-Tuning/Low Rank Adaptation of LLMs, Model Agnostic Meta Learning Generative Models ","permalink":"https://azhara001.github.io/education/grad/","summary":"Master in Information Management and System - Data Science and Machine Learning","title":"University of California, Berkeley"},{"content":" üëãüèº Hello there, I'm Abdullah Azhar! üéì Education: Recent master's graduate from UC Berkeley with a strong focus in Data Science. [ relevant coursework ] üë®üèª‚Äçüíª Professional Experience: Over 2 years as a Data Scientist, handling large, complex datasets across various modalities including tabular, text, vision, and image-to-text. Expertise in computer vision, natural language processing, and traditional machine learning. üîç Career Objective: Seeking Data Scientist and Machine Learning Engineer roles to utilize my strong coding skills in Python, SQL, and R, and my proficiency with PyTorch and Hugging Face's open-source libraries to design, develop, and deploy innovative machine learning solutions. üîÑ Recent Highlights: Data scientist at Lawrence Livermore National Lab focused on predicting groundwater ages in California's Central Valley to address water contamination. [ link to preprint ] üöÄ Capstone Project: Led the end-to-end development of a machine learning model, handling everything from literature review and prototype design to architecture development and fine-tuning, showcasing my capability to manage the entire model lifecycle. [ presentation, code, website ] üõ†Ô∏è Technical Skills: Proficient in Python, SQL, and R, with extensive experience in PyTorch and Hugging Face. Capable of researching, implementing, and fine-tuning state-of-the-art models. View My Resume ","permalink":"https://azhara001.github.io/about/","summary":"Information about me.","title":"About Me"},{"content":" üìö Coursework: ","permalink":"https://azhara001.github.io/education/undergrad/","summary":"\u003col start=\"2\"\u003e\n\u003cli\u003eBachelors in Electrical and Computer Engineering - Class of 2018\u003c/li\u003e\n\u003c/ol\u003e\n","title":"Lahore University of Management Sciences"},{"content":"Content credits: Prof. Jonathan Richard Shewchuk and Prof. Anant Sahai Snapshot Glimpse\nContent\n","permalink":"https://azhara001.github.io/digital_notes/unsupervised_learning/","summary":"Unsupervised learning. Principal components analysis (PCA). Derivations from maximum likelihood estimation, maximizing the variance, and minimizing the sum of squared projection errors. Eigenfaces for face recognition. The singular value decomposition (SVD) and its application to PCA. Clustering: k-means clustering aka Lloyd\u0026rsquo;s algorithm; k-medoids clustering; hierarchical clustering; greedy agglomerative clustering. Dendrograms. The geometry of high-dimensional spaces. Random projection. The pseudoinverse and its relationship to the singular value decomposition.","title":"Unsupervised Learning"}]