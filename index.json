[{"content":" [ Presentation, Demo, Github, Website, Report ] ğŸ“ Completed a final CAPSTONE project in collaboration with Refiberd, working alongside an exceptional team including Isidora Rollan , Erin Jones, Mustafa Hameed , and Prashant Sharma. ğŸ”§ğŸ§© Prototyped an image-to-text captioning system for Refiberd projecting reduced workforce requirements for label collection by 50%, thereby saving 1,500 annual work hours. ğŸ’¡ Conceptualized, tested, and finalized the ML model, followed by fine-tuning and deployment preparation. ğŸ§ ğŸ’» Optimized the state-of-the-art multimodal encoder-decoder DONUT model, achieving an exceptional normalized Levenshtein distance of 0.05. ğŸ—„ï¸ğŸ“Š Developed a custom dataset by sourcing raw images of vendor tags and converting them into the Hugging Face Apache Arrow format, enhancing model training efficiency. ğŸ—ï¸ğŸ“Š Assembled Train Dataset: 469 Images ğŸ”§ğŸ“Š Tuned Validation Dataset: 112 Images ğŸ¯ğŸ“Š Evaluated Test Dataset: 66 Images. ğŸ” Developed a custom PyTorch training loop, logging key metrics such as train loss, validation accuracy, and test accuracy, while also synchronizing model states and checkpoints with the Hugging Face Hub. âš™ï¸ Explored and tuned hyperparameters, experimenting with various optimizers including SGD, SGD with momentum, and second-order optimizers like Adam and AdamW to enhance model performance. ğŸ–¥ï¸ Leveraged L4 GPU architecture to enhance training loops, efficiently managing GPU resources for improved model training workflows. ğŸ† Achieved a perfect match on 47 out of 66 test images underscoring the model's robustness to out-of-distribution data. âš–ï¸ Attained a Cross Entropy Loss of just 0.0005 on the training dataset for the decoder's next-token-prediction task, indicating high predictive accuracy. ğŸ” Currently developing an attention mask using output_state and BertViz for the decoder side to enhance insight into the attention mechanisms within the model. ","permalink":"https://azhara001.github.io/projects/capstone/","summary":"Keywords - Deep Learning, Multi-Modal, Image-to-Text, Multiheaded Attention, Encoder-Decoder, PyTorch, Hugging Face, GPU, SGD, AdamW, Levenshtein Distance, Cross Entropy Loss, Attention Mask","title":"Fine Tuning OCR Free Document Understanding Transformer for Image-to-Text Captioning"},{"content":" [ Preprint, Github, Motivation] ğŸ” Explored the ability of GPT2 Custom Configured Transformer Architecture (22M Params) to in-context learn noisy decision tree algorithm ğŸ§± Built upon the research conducted by garg2023transformers by incorporating:\na) Random Quadrant Prompting, b) Train-Test Overlapping Prompting for noise-free trained checkpoints on decision trees ğŸ§ª Additionally, tested the model's robustness by training it with i.i.d. Gaussian noise at standard deviations of 0, 1, and 3 Choice of Parameters: Batch Size: 64 Learning Rate: 1e-4 Tree Depth: 4 Number of Dimensions: 8 In-Context Examples: 40 â³ Ongoing project due to computational demands required to train a transformer model from scratch and the novelty of the issue. Readers are encouraged to review the preprint for preliminary results. ","permalink":"https://azhara001.github.io/projects/in-context-learning/","summary":"Keywords - Deep Learning, LLMs, GPT2, In-Context-Learning, Pre-Training, PyTorch, Decision Trees, Gaussian Distribution, Noisy Training, Out-of-Distribution, Prompting, Root-Mean-Squared-Error","title":"Adapting to Context: A Case Study on In-Context Learning of Decision Tree Algorithms by Large Language Models"},{"content":" [ publication]\nWork performed as a Data Science Intern at Lawrence Livermore National Lab. Paper published in Water Resources Research (WRR) at the American Geophysical Union (AGU). Abstract: Groundwater ages provides insight into recharge rates, flow velocities, and vulnerability to contaminants. The ability to predict groundwater ages based on more accessible parameters via Machine Learning (ML) would advance our ability to guide sustainable management of groundwater resources. In this study, ML models were trained and tested on a large dataset of tritium concentrations (n=2410) and tritium-helium groundwater ages (n=1157) from the California Central Valley, a large groundwater basin with complex land use, irrigation, and water management practices. The ML models were trained on 63 features, including location, well construction information, landscape characteristics, and climate variables, water chemistry, and stable isotopes. The Bagging Regressor ML method can accurately classify (F1-score = 0.91) groundwater samples as either modern or pre-modern whereas the accuracy of the ML prediction of continuous tritium-helium groundwater ages is limited and explains only ~30% of the variability in this dataset. In general, ML groundwater age prediction relies mostly on features related to (1) the source of groundwater recharge, (2) contaminant history, (3) aquifer materials, (4) well construction, and (5) geochemical reactions along flow paths.\n","permalink":"https://azhara001.github.io/publications-and-preprints/ground-water-predictions/","summary":"Keywords - Machine Learning, Decision Trees, BAGGING, RandomForests, Boosting, Ensemble Learning, Partial Dependence Plots, Feature Importance Plots","title":"Machine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA"},{"content":" [ Preprint, Poster, Github ] ğŸ—„ï¸ğŸ“Š Dataset: MPII - 1463 images with an 80/20 training/validation split ğŸ¤– Model: Bootstrapping Language-Image Pre-Training for Unified Vision-Language Understanding and Generation (BLIP) ğŸ¤—: Source Code ğŸ“‰ Training Loss: Language Modelling Loss from Text Decoder ğŸ“ Evaluation Metric: Mean Absolute Error (MAE) [PyTorch] âš–ï¸ Validation Threshold Range: [1, 5, 25] pixels âš™ï¸ Hyperparameter choice: Batch size: 4 Learning Rate: 2e-5 Optimizer: AdamW ğŸ¯ Validation Accuracy of 92.5% with a threshold of 25 pixels ","permalink":"https://azhara001.github.io/projects/fine-tuning-blip/","summary":"Keywords - Deep Learning, BLIP, Vision Transformer (ViT), Fine-Tuning, Vision-Language Pretraining (VLP), PyTorch, Mean Absolute Error (MAE), Causal Language Modelling, Self-Attention","title":"Fine-tuning Vision Transformer-Based Model for Pose-Estimation"},{"content":" Canonical Basis (EigenFaces)\n[ Github]\nğŸ“ Description: The \"Facial Recognition using Fisher Faces vs Eigen Faces with Support Vector Machines\" project aimed to develop a robust face recognition algorithm leveraging supervised learning techniques. Two feature extraction methods were explored: Eigenfaces and Fisherfaces. Support Vector Machines (SVMs) were then trained using these features to classify faces accurately.\nğŸ–¼ï¸ Datasets Used: Olivetti Dataset: 400 images, 40 classes, 4096 features per image. Labelled Faces in the Wild (LFW) Dataset: 1850 images, user-defined classes, 62500 features per image. Labelled Faces in the Wild (unprocessed) Dataset: 62500 features per image. ğŸ› ï¸ Methodology: Feature Extraction: Eigenfaces: Utilized PCA to extract eigenfaces from the image datasets. Fisherfaces: Implemented Fisher Linear Discriminant Analysis (FLDA) to extract discriminant features. Classification: SVMs with Linear and Radial Basis Function (RBF) kernels were trained using the extracted features. Evaluation: The performance of classifiers was evaluated using metrics like accuracy, precision, recall, and F1-score. Exploratory Data Analysis (EDA) techniques such as t-SNE visualization were employed to analyze dataset distributions. ğŸ”‘ Key Findings: Eigenfaces vs Fisherfaces: Fisherfaces showed improved classification performance compared to Eigenfaces, especially for complex datasets. SVM Kernel Comparison: Linear SVMs outperformed non-linear (RBF) SVMs for most datasets. Dataset Complexity: Performance varied based on dataset complexity, with higher accuracy achieved on simpler datasets. Impact of Dimensionality Reduction: Dimensionality reduction techniques like PCA significantly influenced classifier performance. ğŸ Conclusion: The project demonstrated the efficacy of Fisherfaces combined with SVMs for face recognition tasks. By comparing different feature extraction methods and SVM configurations, valuable insights were gained into the nuances of facial recognition systems. The findings contribute to the ongoing research in computer vision and pattern recognition domains, paving the way for more accurate and efficient face recognition algorithms.\n","permalink":"https://azhara001.github.io/projects/facial-recognition/","summary":"Keywords - Support Vector Machines, Principal Component Analysis, Eigen Faces, Fisher Faces, Linear Discriminant Analysis","title":"Facial Recognition using eigenfaces/fisherfaces using an SVM Classifier"},{"content":" Spatio-temporal Heat Map\n[ Article, Poster, Github, Conference Presentation ] ğŸ“ Description: This project delved into the intricate relationship between school closures, traffic congestion, and smog in Lahore, Pakistan. As part of the Smart Data Systems and Applications (SDSA) team at Lahore University of Management Sciences (LUMS), we aimed to leverage data-driven analysis to understand the effectiveness of closing schools on Mondays in reducing traffic congestion and ultimately alleviating smog.\nğŸ¯ Objectives: Investigate the impact of school closure policies on traffic congestion levels in Lahore. Analyze the correlation between traffic congestion reduction and improvements in air quality, particularly regarding smog levels. Provide insights and recommendations based on data-driven findings to inform future policy decisions and urban planning initiatives. ğŸ› ï¸ Methodology: Utilized the Google Maps Platform to extract data on travel times, routes, and congestion levels in Lahore. Conducted data preprocessing, including normalization of travel times and comparison of velocities to assess traffic congestion. Employed statistical analysis techniques to interpret the impact of school closures on traffic congestion before and during the winter break. Visualized findings through graphs, heatmaps, and geospatial mapping to facilitate understanding and communication of results. ğŸ” Results: Identified a significant decrease in traffic congestion on Mondays, particularly during the winter break when schools were closed. Observed a correlation between reduced traffic congestion and improvements in air quality, indicating the potential effectiveness of school closure policies in mitigating smog. Highlighted Thursdays as a day with the greatest decrease in congestion, suggesting alternative strategies beyond Mondays for reducing traffic congestion and smog. ğŸ Conclusion: This project sheds light on the efficacy of school closure policies in addressing traffic congestion and smog in Lahore. By providing actionable insights derived from data analysis, we intended to inform policymakers, urban planners, and stakeholders about effective strategies for mitigating the impact of smog in the region. Our findings underscored the importance of proactive measures and evidence-based decision-making in tackling environmental challenges like smog.\n","permalink":"https://azhara001.github.io/projects/travel-times-analysis/","summary":"Exploring the bittersweet relationship of schoolsâ€™ closure and smog â€“ an effective step in alleviating traffic congestions?","title":"Analyzing Spatio-Temporal Travel Times using Crowd-sourced Data"},{"content":" ğŸ“š Coursework: 1. Designing, Visualizing, and Understanding Deep Neural Networks [ course website, final project, github ] Topics Covered: Choice of optimizers (Stochastic Gradient Descent, Adam, Adam with Momentum) Convolutional Neural Networks, Skip Connections, Batch Normalization Recurrent Neural Networks Transformers (cross-attention, self-attention, argmax attention), Fine-Tuning, Parameter-Efficient Fine-Tuning/Low Rank Adaptation of LLMs, Model Agnostic Meta Learning Generative Models ","permalink":"https://azhara001.github.io/education/grad/","summary":"Master in Information Management and System - Data Science and Machine Learning","title":"University of California, Berkeley"},{"content":" ğŸ‘‹ğŸ¼ Hello there, I'm Abdullah Azhar! Data Scientist at Halcyon - Leveraging Machine Learning and AI to inform better decision making in the energy sector ğŸ“ Education: Master's graduate from UC Berkeley (2024) with a strong focus in Data Science. [ relevant coursework ] ğŸ”„ Recent Publication: Data scientist at Lawrence Livermore National Lab focused on predicting groundwater ages in California's Central Valley using statistical decision tree regressors to address water contamination. [ published in AGU ] ğŸ‘¨ğŸ»â€ğŸ’» Professional Experience: Over 3 years as a Data Scientist, handling large, complex datasets across various modalities including tabular, text, vision, and image-to-text. Expertise in computer vision, natural language processing, and traditional machine learning. ğŸš€ Capstone Project: Led the end-to-end development of a machine learning model, handling everything from literature review and prototype design to architecture development and fine-tuning, showcasing my capability to manage the entire model lifecycle. [ presentation, code, website ] ğŸ› ï¸ Technical Skills: Proficient in Python, SQL, and R, with extensive experience in PyTorch, Hugging Face, and Scikit-learn. Capable of researching, implementing, and fine-tuning state-of-the-art models. ","permalink":"https://azhara001.github.io/about/","summary":"Information about me.","title":"About Me"},{"content":" ğŸ“š Coursework: ","permalink":"https://azhara001.github.io/education/undergrad/","summary":"\u003col start=\"2\"\u003e\n\u003cli\u003eBachelors in Electrical and Computer Engineering - Class of 2018\u003c/li\u003e\n\u003c/ol\u003e\n","title":"Lahore University of Management Sciences"},{"content":"Content credits: Prof. Jonathan Richard Shewchuk and Prof. Anant Sahai Snapshot Glimpse\nContent\n","permalink":"https://azhara001.github.io/digital_notes/unsupervised_learning/","summary":"Unsupervised learning. Principal components analysis (PCA). Derivations from maximum likelihood estimation, maximizing the variance, and minimizing the sum of squared projection errors. Eigenfaces for face recognition. The singular value decomposition (SVD) and its application to PCA. Clustering: k-means clustering aka Lloyd\u0026rsquo;s algorithm; k-medoids clustering; hierarchical clustering; greedy agglomerative clustering. Dendrograms. The geometry of high-dimensional spaces. Random projection. The pseudoinverse and its relationship to the singular value decomposition.","title":"Unsupervised Learning"}]