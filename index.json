[{"content":" [ Presentation, Demo, Github, Website, Report ] üéì Completed a final CAPSTONE project in collaboration with Refiberd, working alongside an exceptional team including Isidora Rollan , Erin Jones, Mustafa Hameed , and Prashant Sharma. üîßüß© Prototyped an image-to-text captioning system for Refiberd projecting reduced workforce requirements for label collection by 50%, thereby saving 1,500 annual work hours. üí° Conceptualized, tested, and finalized the ML model, followed by fine-tuning and deployment preparation. üß†üíª Optimized the state-of-the-art multimodal encoder-decoder DONUT model, achieving an exceptional normalized Levenshtein distance of 0.005. üóÑÔ∏èüìä Developed a custom dataset by sourcing raw images of vendor tags and converting them into the Hugging Face Apache Arrow format, enhancing model training efficiency. üèóÔ∏èüìä Assembled Train Dataset: 469 Images üîßüìä Tuned Validation Dataset: 112 Images üéØüìä Evaluated Test Dataset: 66 Images. üîÅ Developed a custom PyTorch training loop, logging key metrics such as train loss, validation accuracy, and test accuracy, while also synchronizing model states and checkpoints with the Hugging Face Hub. ‚öôÔ∏è Explored and tuned hyperparameters, experimenting with various optimizers including SGD, SGD with momentum, and second-order optimizers like Adam and AdamW to enhance model performance. üñ•Ô∏è Leveraged L4 GPU architecture to enhance training loops, efficiently managing GPU resources for improved model training workflows. üèÜ Achieved a perfect match on 47 out of 66 test images, demonstrating a Levenshtein score of 0 and underscoring the model's robustness. ‚öñÔ∏è Attained a Cross Entropy Loss of just 0.0005 on the training dataset for the decoder's next-token-prediction task, indicating high predictive accuracy. üîç Currently developing an attention mask using output_state and BertViz for the decoder side to enhance insight into the attention mechanisms within the model. ","permalink":"https://azhara001.github.io/projects/capstone/","summary":"Keywords - Multi-Modal, Image-to-Text, Multiheaded Attention, Encoder-Decoder, PyTorch, Hugging Face, GPU, SGD, AdamW, Levenshtein Distance, Cross Entropy Loss, Attention Mask","title":"Fine Tuning OCR Free Document Understanding Transformer for Image-to-Text Captioning"},{"content":"Work performed as a Computing Scholar Intern at Lawrence Livermore National Lab.\nMachine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA Abstract: Groundwater ages provides insight into recharge rates, flow velocities, and vulnerability to contaminants. The ability to predict groundwater ages based on more accessible parameters via Machine Learning (ML) would advance our ability to guide sustainable management of groundwater resources. In this study, ML models were trained and tested on a large dataset of tritium concentrations ($n=2410$) and tritium-helium groundwater ages ($n=1157$) from the California Central Valley, a large groundwater basin with complex land use, irrigation, and water management practices. The ML models were trained on $63$ features, including location, well construction information, landscape characteristics, and climate variables, water chemistry, and stable isotopes. The Bagging Regressor ML method can accurately classify (F1-score = $0.91$) groundwater samples as either modern or pre-modern whereas the accuracy of the ML prediction of continuous tritium-helium groundwater ages is limited and explains only $\\sim 30%$ of the variability in this dataset. In general, ML groundwater age prediction relies mostly on features related to (1) the source of groundwater recharge, (2) contaminant history, (3) aquifer materials, (4) well construction, and (5) geochemical reactions along flow paths. Link to Preprint ","permalink":"https://azhara001.github.io/publications-and-preprints/ground-water-predictions/","summary":"Azhar, A., Chakraborty, I., Visser, A., Liu, Y., Lerback, J. C., \u0026amp; Oerter, E. Machine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA. California, USA.","title":"Machine Learning Prediction of Tritium-Helium Groundwater Ages in the Central Valley, California, USA"},{"content":"FINE-TUNING VISION TRANSFORMER-BASED MODEL FOR POSE-ESTIMATION Abstract: With the development of the Computer Vision discipline within Deep Learning, Pose Estimation tasks have seen increasing interest and growth in the past decade. Pose Estimation refers to the problem of localizing specific body parts in images and videos and encoding the spatial information into a caption relating human skeletal joints with pixel coordinates. While Pose Estimation models have largely been Convolutional Neural Network (CNN)-based, the advent of Vision Transformers (ViT) has opened new areas of research. In this study, we fine-tune a transformer-based model, BLIP, to generate accurate positional captions and explore attention mechanisms under this task. Starting with a low-complexity version of our problem, we scaled up to our task of fine-tuning BLIP for Pose Estimation. After fine-tuning BLIP on varying hyperparameters, we found that the model consistently performed well during tuning. Within a restricted threshold of 1 pixel, it retained an 81% validation accuracy and an average error of about 4 pixels. Link to Preprint Code ","permalink":"https://azhara001.github.io/publications-and-preprints/blip/","summary":"Jinxuan Liang, Yihua Zhou, Abdullah Azhar, Anjana Manjunath University of California, Berkeley","title":"Human Pose Estimation using BLIP"},{"content":" [ Preprint, Poster, Github ] üóÑÔ∏èüìä Dataset: MPII - 1463 images with an 80/20 training/validation split ü§ñ Model: Bootstrapping Language-Image Pre-Training for Unified Vision-Language Understanding and Generation (BLIP) ü§ó: Source Code üìâ Training Loss: Language Modelling Loss from Text Decoder üìè Evaluation Metric: Mean Absolute Error (MAE) [PyTorch] ‚öñÔ∏è Validation Threshold Range: [1, 5, 25] pixels ‚öôÔ∏è Hyperparameter choice: Batch size: 4 Learning Rate: 2e-5 Optimizer: AdamW üéØ Validation Accuracy of 92.5% with a threshold of 25 pixels ","permalink":"https://azhara001.github.io/projects/fine-tuning-blip/","summary":"Keywords - BLIP, Vision Transformer (ViT), Fine-Tuning, Vision-Language Pretraining (VLP), PyTorch, Mean Absolute Error (MAE), Causal Language Modelling, Self-Attention","title":"Fine-tuning Vision Transformer-Based Model for Pose-Estimation"},{"content":" Canonical Basis (EigenFaces)\nLinks: Github Description: The \u0026ldquo;Facial Recognition using Fisher Faces vs Eigen Faces with Support Vector Machines\u0026rdquo; project aimed to develop a robust face recognition algorithm leveraging supervised learning techniques. Two feature extraction methods were explored: Eigenfaces and Fisherfaces. Support Vector Machines (SVMs) were then trained using these features to classify faces accurately.\nDatasets Used: Olivetti Dataset: 400 images, 40 classes, 4096 features per image. Labelled Faces in the Wild (LFW) Dataset: 1850 images, user-defined classes, 62500 features per image. Labelled Faces in the Wild (unprocessed) Dataset: 62500 features per image. Methodology: Feature Extraction: Eigenfaces: Utilized PCA to extract eigenfaces from the image datasets. Fisherfaces: Implemented Fisher Linear Discriminant Analysis (FLDA) to extract discriminant features.\nClassification: SVMs with Linear and Radial Basis Function (RBF) kernels were trained using the extracted features.\nEvaluation: The performance of classifiers was evaluated using metrics like accuracy, precision, recall, and F1-score. Exploratory Data Analysis (EDA) techniques such as t-SNE visualization were employed to analyze dataset distributions.\nKey Findings: Eigenfaces vs Fisherfaces: Fisherfaces showed improved classification performance compared to Eigenfaces, especially for complex datasets. SVM Kernel Comparison: Linear SVMs outperformed non-linear (RBF) SVMs for most datasets. Dataset Complexity: Performance varied based on dataset complexity, with higher accuracy achieved on simpler datasets. Impact of Dimensionality Reduction: Dimensionality reduction techniques like PCA significantly influenced classifier performance. Conclusion: The project demonstrated the efficacy of Fisherfaces combined with SVMs for face recognition tasks. By comparing different feature extraction methods and SVM configurations, valuable insights were gained into the nuances of facial recognition systems. The findings contribute to the ongoing research in computer vision and pattern recognition domains, paving the way for more accurate and efficient face recognition algorithms\n","permalink":"https://azhara001.github.io/projects/facial-recognition/","summary":"Keywords -","title":"Facial Recognition using eigenfaces/fisherfaces using an SVM Classifier"},{"content":" Spatio-temporal Heat Map\nLinks: Article Poster Github Conference Presentation Description: This project delved into the intricate relationship between school closures, traffic congestion, and smog in Lahore, Pakistan. As part of the Smart Data Systems and Applications (SDSA) team at Lahore University of Management Sciences (LUMS), we aimed to leverage data-driven analysis to understand the effectiveness of closing schools on Mondays in reducing traffic congestion and ultimately alleviating smog.\nObjectives: Investigate the impact of school closure policies on traffic congestion levels in Lahore. Analyze the correlation between traffic congestion reduction and improvements in air quality, particularly regarding smog levels. Provide insights and recommendations based on data-driven findings to inform future policy decisions and urban planning initiatives.\nMethodology: Utilized the Google Maps Platform to extract data on travel times, routes, and congestion levels in Lahore. Conducted data preprocessing, including normalization of travel times and comparison of velocities to assess traffic congestion. Employed statistical analysis techniques to interpret the impact of school closures on traffic congestion before and during the winter break. Visualized findings through graphs, heatmaps, and geospatial mapping to facilitate understanding and communication of results.\nResults: Identified a significant decrease in traffic congestion on Mondays, particularly during the winter break when schools were closed. Observed a correlation between reduced traffic congestion and improvements in air quality, indicating the potential effectiveness of school closure policies in mitigating smog. Highlighted Thursdays as a day with the greatest decrease in congestion, suggesting alternative strategies beyond Mondays for reducing traffic congestion and smog.\nConclusion: This project sheds light on the efficacy of school closure policies in addressing traffic congestion and smog in Lahore. By providing actionable insights derived from data analysis, we intended to inform policymakers, urban planners, and stakeholders about effective strategies for mitigating the impact of smog in the region. Our findings underscored the importance of proactive measures and evidence-based decision-making in tackling environmental challenges like smog.\n","permalink":"https://azhara001.github.io/projects/travel-times-analysis/","summary":"Exploring the bittersweet relationship of schools‚Äô closure and smog ‚Äì an effective step in alleviating traffic congestions?","title":"Analyzing Spatio-Temporal Travel Times using Crowd-sourced Data"},{"content":" üìö Coursework: 1. Designing, Visualizing, and Understanding Deep Neural Networks [ course website, final project, github ] Topics Covered: Choice of optimizers (Stochastic Gradient Descent, Adam, Adam with Momentum) Convolutional Neural Networks, Skip Connections, Batch Normalization Recurrent Neural Networks Transformers (cross-attention, self-attention, argmax attention), Fine-Tuning, Parameter-Efficient Fine-Tuning/Low Rank Adaptation of LLMs, Model Agnostic Meta Learning Generative Models ","permalink":"https://azhara001.github.io/education/grad/","summary":"Master in Information Management and System - Data Science and Machine Learning","title":"University of California, Berkeley"},{"content":" üëãüèº Hello there, I'm Abdullah Azhar! üéì Education: Recent master's graduate from UC Berkeley with a strong focus in Data Science. [ relevant coursework ] üë®üèª‚Äçüíª Professional Experience: Over 2 years as a Data Scientist, handling large, complex datasets across various modalities including tabular, text, vision, and image-to-text. Expertise in computer vision, natural language processing, and traditional machine learning. üîç Career Objective: Seeking Applied Scientist, Data Scientist or Machine Learning Engineer roles to design, develop, and prototype innovative and data-centric machine learning solutions. üîÑ Recent Highlights: Data scientist at Lawrence Livermore National Lab focused on predicting groundwater ages in California's Central Valley using statistical decision tree regressors to address water contamination. [ link to preprint ] üöÄ Capstone Project: Led the end-to-end development of a machine learning model, handling everything from literature review and prototype design to architecture development and fine-tuning, showcasing my capability to manage the entire model lifecycle. [ presentation, code, website ] üõ†Ô∏è Technical Skills: Proficient in Python, SQL, and R, with extensive experience in PyTorch, Hugging Face, and Scikit-learn. Capable of researching, implementing, and fine-tuning state-of-the-art models. ","permalink":"https://azhara001.github.io/about/","summary":"Information about me.","title":"About Me"},{"content":" üìö Coursework: ","permalink":"https://azhara001.github.io/education/undergrad/","summary":"\u003col start=\"2\"\u003e\n\u003cli\u003eBachelors in Electrical and Computer Engineering - Class of 2018\u003c/li\u003e\n\u003c/ol\u003e\n","title":"Lahore University of Management Sciences"},{"content":"Content credits: Prof. Jonathan Richard Shewchuk and Prof. Anant Sahai Snapshot Glimpse\nContent\n","permalink":"https://azhara001.github.io/digital_notes/unsupervised_learning/","summary":"Unsupervised learning. Principal components analysis (PCA). Derivations from maximum likelihood estimation, maximizing the variance, and minimizing the sum of squared projection errors. Eigenfaces for face recognition. The singular value decomposition (SVD) and its application to PCA. Clustering: k-means clustering aka Lloyd\u0026rsquo;s algorithm; k-medoids clustering; hierarchical clustering; greedy agglomerative clustering. Dendrograms. The geometry of high-dimensional spaces. Random projection. The pseudoinverse and its relationship to the singular value decomposition.","title":"Unsupervised Learning"}]